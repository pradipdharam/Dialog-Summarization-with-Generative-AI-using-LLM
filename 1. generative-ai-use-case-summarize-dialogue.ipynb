{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Generative AI Use Case: Dialogue Summarization using FLAN-T5 LLM\n\nWelcome to the practical side of this course. In this lab you will do the dialogue summarization task using generative AI. You will explore how the input text affects the output of the model, and perform prompt engineering to direct it towards the task you need. By comparing zero shot, one shot, and few shot inferences, you will take the first step towards prompt engineering and see how it can enhance the generative output of Large Language Models.","metadata":{}},{"cell_type":"markdown","source":"##### Citations and Credits\n- This is the hands-on execise lab 1 assignment completed as part of \"Generative AI with Large Language Models\" couse on Coursera.com.","metadata":{}},{"cell_type":"markdown","source":"# Exercise Content","metadata":{}},{"cell_type":"markdown","source":"- [ 1 - Set up Kernel and Required Dependencies](#1)\n- [ 2 - Summarize Dialogue without Prompt Engineering](#2)\n- [ 3 - Summarize Dialogue with an Instruction Prompt](#3)\n  - [ 3.1 - Zero Shot Inference with an Instruction Prompt](#3.1)\n  - [ 3.2 - Zero Shot Inference with the Prompt Template from FLAN-T5](#3.2)\n- [ 4 - Summarize Dialogue with One Shot and Few Shot Inference](#4)\n  - [ 4.1 - One Shot Inference](#4.1)\n  - [ 4.2 - Few Shot Inference](#4.2)\n- [ 5 - Generative Configuration Parameters for Inference](#5)\n","metadata":{}},{"cell_type":"markdown","source":"<a name='1'></a>\n## 1 - Set up Kernel and Required Dependencies","metadata":{}},{"cell_type":"code","source":"%pip install --upgrade pip\n%pip install --disable-pip-version-check \\\n    torch==1.13.1 \\\n    torchdata==0.5.1 --quiet\n\n%pip install \\\n    transformers==4.27.2 \\\n    datasets==2.11.0  --quiet","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:37:46.169002Z","iopub.execute_input":"2023-08-05T17:37:46.173697Z","iopub.status.idle":"2023-08-05T17:40:24.448375Z","shell.execute_reply.started":"2023-08-05T17:37:46.173506Z","shell.execute_reply":"2023-08-05T17:40:24.446801Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.2.1)\nNote: you may need to restart the kernel to use updated packages.\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorchaudio 2.0.1+cpu requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\ntorchtext 0.15.1+cpu requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\ntorchtext 0.15.1+cpu requires torchdata==0.6.0, but you have torchdata 0.5.1 which is incompatible.\ntorchvision 0.15.1+cpu requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSI1MCIgdmlld0JveD0iMCAwIDgwMCA1MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxkZWZzPgogICAgICAgIDxsaW5lYXJHcmFkaWVudCBpZD0iZmFkZUdyYWRpZW50IiB4MT0iMCIgeDI9IjEiPgogICAgICAgICAgICA8c3RvcCBvZmZzZXQ9IjAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIi8+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMTAwJSIgc3RvcC1jb2xvcj0iI0YwRjBGMCIgc3RvcC1vcGFjaXR5PSIwIi8+CiAgICAgICAgPC9saW5lYXJHcmFkaWVudD4KICAgICAgICA8bWFzayBpZD0iZmFkZU1hc2siPgogICAgICAgICAgICA8cmVjdCB4PSIwIiB5PSIwIiB3aWR0aD0iNzUwIiBoZWlnaHQ9IjUwIiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSI1MCIgZmlsbD0idXJsKCNmYWRlR3JhZGllbnQpIi8+CiAgICAgICAgPC9tYXNrPgogICAgPC9kZWZzPgogICAgPHBhdGggZD0iTTI1LDUwIFEwLDUwIDAsMjUgTDUwLDMgTDk3LDI1IEw3OTcsMjUgTDc5Nyw1MCBMMjUsNTAgWiIgZmlsbD0iI0YwRjBGMCIgc3Ryb2tlPSIjRTBFMEUwIiBzdHJva2Utd2lkdGg9IjEiIG1hc2s9InVybCgjZmFkZU1hc2spIi8+Cjwvc3ZnPgo=\" alt=\"Time alert close\"/>","metadata":{"tags":[]}},{"cell_type":"markdown","source":"Load the datasets, Large Language Model (LLM), tokenizer, and configurator. Do not worry if you do not understand yet all of those components - they will be described and discussed later in the notebook.","metadata":{"tags":[]}},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import AutoModelForSeq2SeqLM\nfrom transformers import AutoTokenizer\nfrom transformers import GenerationConfig","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:40:24.451114Z","iopub.execute_input":"2023-08-05T17:40:24.451565Z","iopub.status.idle":"2023-08-05T17:40:27.632025Z","shell.execute_reply.started":"2023-08-05T17:40:24.451505Z","shell.execute_reply":"2023-08-05T17:40:27.630595Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"<a name='2'></a>\n## 2 - Summarize Dialogue without Prompt Engineering\n\nIn this use case, you will be generating a summary of a dialogue with the pre-trained Large Language Model (LLM) FLAN-T5 from Hugging Face. The list of available models in the Hugging Face `transformers` package can be found [here](https://huggingface.co/docs/transformers/index). \n\nLet's upload some simple dialogues from the [DialogSum](https://huggingface.co/datasets/knkarthick/dialogsum) Hugging Face dataset. This dataset contains 10,000+ dialogues with the corresponding manually labeled summaries and topics. ","metadata":{}},{"cell_type":"code","source":"huggingface_dataset_name = \"knkarthick/dialogsum\"\n\ndataset = load_dataset(huggingface_dataset_name)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:40:27.636201Z","iopub.execute_input":"2023-08-05T17:40:27.637135Z","iopub.status.idle":"2023-08-05T17:40:31.190388Z","shell.execute_reply.started":"2023-08-05T17:40:27.637092Z","shell.execute_reply":"2023-08-05T17:40:31.188870Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/4.56k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95cf961aaff54ac08e215774826e0c16"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"Downloading and preparing dataset csv/knkarthick--dialogsum to /root/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-c8fac5d84cd35861/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65aff7c50dc6450d911a76874ce2a6a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/11.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03812b199dd54b02a5eaed2781f80300"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a23cf6dc0bc4e98ab217886fb58bd02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/442k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71a4acfe3f7945c28e9994169afb2cce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b674ad96b9ed4c6db0732fbd56752621"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-c8fac5d84cd35861/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7720607cb964c5bb24c6b9cb63c2d92"}},"metadata":{}}]},{"cell_type":"markdown","source":"Print a couple of dialogues with their baseline summaries.","metadata":{"tags":[]}},{"cell_type":"code","source":"example_indices = [40, 200]\n\ndash_line = '-'.join('' for x in range(100))\n\nfor i, index in enumerate(example_indices):\n    print(dash_line)\n    print('Example ', i + 1)\n    print(dash_line)\n    print('INPUT DIALOGUE:')\n    print(dataset['test'][index]['dialogue'])\n    print(dash_line)\n    print('BASELINE HUMAN SUMMARY:')\n    print(dataset['test'][index]['summary'])\n    print(dash_line)\n    print()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:40:31.192165Z","iopub.execute_input":"2023-08-05T17:40:31.192548Z","iopub.status.idle":"2023-08-05T17:40:31.204912Z","shell.execute_reply.started":"2023-08-05T17:40:31.192515Z","shell.execute_reply":"2023-08-05T17:40:31.203381Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nExample  1\n---------------------------------------------------------------------------------------------------\nINPUT DIALOGUE:\n#Person1#: What time is it, Tom?\n#Person2#: Just a minute. It's ten to nine by my watch.\n#Person1#: Is it? I had no idea it was so late. I must be off now.\n#Person2#: What's the hurry?\n#Person1#: I must catch the nine-thirty train.\n#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n---------------------------------------------------------------------------------------------------\n\n---------------------------------------------------------------------------------------------------\nExample  2\n---------------------------------------------------------------------------------------------------\nINPUT DIALOGUE:\n#Person1#: Have you considered upgrading your system?\n#Person2#: Yes, but I'm not sure what exactly I would need.\n#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n#Person2#: That would be a definite bonus.\n#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n#Person2#: How can we do that?\n#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n#Person2#: No.\n#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n#Person2#: That sounds great. Thanks.\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n---------------------------------------------------------------------------------------------------\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Load the [FLAN-T5 model](https://huggingface.co/docs/transformers/model_doc/flan-t5), creating an instance of the `AutoModelForSeq2SeqLM` class with the `.from_pretrained()` method. ","metadata":{}},{"cell_type":"code","source":"model_name='google/flan-t5-base'\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)","metadata":{"id":"iAYlS40Z3l-v","tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:40:31.210109Z","iopub.execute_input":"2023-08-05T17:40:31.210691Z","iopub.status.idle":"2023-08-05T17:40:42.265282Z","shell.execute_reply.started":"2023-08-05T17:40:31.210640Z","shell.execute_reply":"2023-08-05T17:40:42.264031Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a29d8843266445aa720c78248cc55e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d19353201a9b40d699b0e0ec95d04578"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae9049752ecc41968fc7d0e661da0a8a"}},"metadata":{}}]},{"cell_type":"markdown","source":"To perform encoding and decoding, you need to work with text in a tokenized form. **Tokenization** is the process of splitting texts into smaller units that can be processed by the LLM models. \n\nDownload the tokenizer for the FLAN-T5 model using `AutoTokenizer.from_pretrained()` method. Parameter `use_fast` switches on fast tokenizer. At this stage, there is no need to go into the details of that, but you can find the tokenizer parameters in the [documentation](https://huggingface.co/docs/transformers/v4.28.1/en/model_doc/auto#transformers.AutoTokenizer).","metadata":{"id":"sPqQA3TT3l_I","tags":[]}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)","metadata":{"id":"sPqQA3TT3l_I","tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:40:42.266999Z","iopub.execute_input":"2023-08-05T17:40:42.267394Z","iopub.status.idle":"2023-08-05T17:40:43.415508Z","shell.execute_reply.started":"2023-08-05T17:40:42.267348Z","shell.execute_reply":"2023-08-05T17:40:43.414099Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8b9d45f11de4da099bf16728ab86b35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66d7444558104f78b9fcdbe8eb6b135b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae0af9c2cf934c00997e708303762902"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e49ed3ff668a441f96ab06cd4b5bca75"}},"metadata":{}}]},{"cell_type":"markdown","source":"Test the tokenizer encoding and decoding a simple sentence:","metadata":{"tags":[]}},{"cell_type":"code","source":"sentence = \"What time is it, Tom?\"\n\nsentence_encoded = tokenizer(sentence, return_tensors='pt')\n\nsentence_decoded = tokenizer.decode(\n        sentence_encoded[\"input_ids\"][0], \n        skip_special_tokens=True\n    )\n\nprint('ENCODED SENTENCE:')\nprint(sentence_encoded[\"input_ids\"][0])\nprint('\\nDECODED SENTENCE:')\nprint(sentence_decoded)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:40:43.416908Z","iopub.execute_input":"2023-08-05T17:40:43.417397Z","iopub.status.idle":"2023-08-05T17:40:52.932371Z","shell.execute_reply.started":"2023-08-05T17:40:43.417348Z","shell.execute_reply":"2023-08-05T17:40:52.931108Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"name":"stdout","text":"ENCODED SENTENCE:\ntensor([ 363,   97,   19,   34,    6, 3059,   58,    1])\n\nDECODED SENTENCE:\nWhat time is it, Tom?\n","output_type":"stream"}]},{"cell_type":"code","source":"print(sentence_encoded)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:40:52.933763Z","iopub.execute_input":"2023-08-05T17:40:52.934105Z","iopub.status.idle":"2023-08-05T17:40:52.948086Z","shell.execute_reply.started":"2023-08-05T17:40:52.934074Z","shell.execute_reply":"2023-08-05T17:40:52.947047Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"{'input_ids': tensor([[ 363,   97,   19,   34,    6, 3059,   58,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now it's time to explore how well the base LLM summarizes a dialogue without any prompt engineering. **Prompt engineering** is an act of a human changing the **prompt** (input) to improve the response for a given task.","metadata":{}},{"cell_type":"code","source":"for i, index in enumerate(example_indices):\n    dialogue = dataset['test'][index]['dialogue']\n    summary = dataset['test'][index]['summary']\n    \n    inputs = tokenizer(dialogue, return_tensors='pt')\n    output = tokenizer.decode(\n        model.generate(\n            inputs[\"input_ids\"], \n            max_new_tokens=50,\n        )[0], \n        skip_special_tokens=True\n    )\n    \n    print(dash_line)\n    print('Example ', i + 1)\n    print(dash_line)\n    print(f'INPUT PROMPT:\\n{dialogue}')\n    print(dash_line)\n    print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n    print(dash_line)\n    print(f'MODEL GENERATION - WITHOUT PROMPT ENGINEERING:\\n{output}\\n')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:40:52.949794Z","iopub.execute_input":"2023-08-05T17:40:52.950455Z","iopub.status.idle":"2023-08-05T17:40:55.862566Z","shell.execute_reply.started":"2023-08-05T17:40:52.950420Z","shell.execute_reply":"2023-08-05T17:40:55.861152Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nExample  1\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n#Person1#: What time is it, Tom?\n#Person2#: Just a minute. It's ten to nine by my watch.\n#Person1#: Is it? I had no idea it was so late. I must be off now.\n#Person2#: What's the hurry?\n#Person1#: I must catch the nine-thirty train.\n#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - WITHOUT PROMPT ENGINEERING:\nPerson1: It's ten to nine.\n\n---------------------------------------------------------------------------------------------------\nExample  2\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n#Person1#: Have you considered upgrading your system?\n#Person2#: Yes, but I'm not sure what exactly I would need.\n#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n#Person2#: That would be a definite bonus.\n#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n#Person2#: How can we do that?\n#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n#Person2#: No.\n#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n#Person2#: That sounds great. Thanks.\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - WITHOUT PROMPT ENGINEERING:\n#Person1#: I'm thinking of upgrading my computer.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model.generate(\n            inputs[\"input_ids\"], \n            max_new_tokens=50,\n        )","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:40:55.864308Z","iopub.execute_input":"2023-08-05T17:40:55.864993Z","iopub.status.idle":"2023-08-05T17:40:57.360581Z","shell.execute_reply.started":"2023-08-05T17:40:55.864948Z","shell.execute_reply":"2023-08-05T17:40:57.359240Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"tensor([[    0,  1713,   345, 13515,   536,  4663,    10,    27,    31,    51,\n          1631,    13, 21066,    82,  1218,     5,     1]])"},"metadata":{}}]},{"cell_type":"markdown","source":"You can see that the guesses of the model make some sense, but it doesn't seem to be sure what task it is supposed to accomplish. Seems it just makes up the next sentence in the dialogue. Prompt engineering can help here.","metadata":{}},{"cell_type":"markdown","source":"<a name='3'></a>\n## 3 - Summarize Dialogue with an Instruction Prompt\n\nPrompt engineering is an important concept in using foundation models for text generation. You can check out [this blog](https://www.amazon.science/blog/emnlp-prompt-engineering-is-the-new-feature-engineering) from Amazon Science for a quick introduction to prompt engineering.","metadata":{}},{"cell_type":"markdown","source":"<a name='3.1'></a>\n### 3.1 - Zero Shot Inference with an Instruction Prompt\n\nIn order to instruct the model to perform a task - summarize a dialogue - you can take the dialogue and convert it into an instruction prompt. This is often called **zero shot inference**.  You can check out [this blog from AWS](https://aws.amazon.com/blogs/machine-learning/zero-shot-prompting-for-the-flan-t5-foundation-model-in-amazon-sagemaker-jumpstart/) for a quick description of what zero shot learning is and why it is an important concept to the LLM model.\n\nWrap the dialogue in a descriptive instruction and see how the generated text will change:","metadata":{}},{"cell_type":"code","source":"for i, index in enumerate(example_indices):\n    dialogue = dataset['test'][index]['dialogue']\n    summary = dataset['test'][index]['summary']\n\n    prompt = f\"\"\"\nSummarize the following conversation.\n\n{dialogue}\n\nSummary:\n    \"\"\"\n\n    # Input constructed prompt instead of the dialogue.\n    inputs = tokenizer(prompt, return_tensors='pt')\n    output = tokenizer.decode(\n        model.generate(\n            inputs[\"input_ids\"], \n            max_new_tokens=50,\n        )[0], \n        skip_special_tokens=True\n    )\n    \n    print(dash_line)\n    print('Example ', i + 1)\n    print(dash_line)\n    print(f'INPUT PROMPT:\\n{prompt}')\n    print(dash_line)\n    print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n    print(dash_line)    \n    print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:40:57.362183Z","iopub.execute_input":"2023-08-05T17:40:57.362612Z","iopub.status.idle":"2023-08-05T17:40:59.710564Z","shell.execute_reply.started":"2023-08-05T17:40:57.362577Z","shell.execute_reply":"2023-08-05T17:40:59.709077Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nExample  1\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n\nSummarize the following conversation.\n\n#Person1#: What time is it, Tom?\n#Person2#: Just a minute. It's ten to nine by my watch.\n#Person1#: Is it? I had no idea it was so late. I must be off now.\n#Person2#: What's the hurry?\n#Person1#: I must catch the nine-thirty train.\n#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n\nSummary:\n    \n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\nThe train is about to leave.\n\n---------------------------------------------------------------------------------------------------\nExample  2\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n\nSummarize the following conversation.\n\n#Person1#: Have you considered upgrading your system?\n#Person2#: Yes, but I'm not sure what exactly I would need.\n#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n#Person2#: That would be a definite bonus.\n#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n#Person2#: How can we do that?\n#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n#Person2#: No.\n#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n#Person2#: That sounds great. Thanks.\n\nSummary:\n    \n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\n#Person1#: I'm thinking of upgrading my computer.\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"This is much better! But the model still does not pick up on the nuance of the conversations though.","metadata":{}},{"cell_type":"markdown","source":"**Exercise:**\n\n- Experiment with the `prompt` text and see how the inferences will be changed. Will the inferences change if you end the prompt with just empty string vs. `Summary: `?\n- Try to rephrase the beginning of the `prompt` text from `Summarize the following conversation.` to something different - and see how it will influence the generated output.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Solving the above mentioned exercise - first point**\n- Experiment with the `prompt` text and see how the inferences will be changed. Will the inferences change if you end the prompt with just empty string vs. `Summary: `\n\n**Observations after soving execrcise for First Point**\n- Inference for example 1 is changed","metadata":{}},{"cell_type":"code","source":"for i, index in enumerate(example_indices):\n    dialogue = dataset['test'][index]['dialogue']\n    summary = dataset['test'][index]['summary']\n\n    prompt = f\"\"\"\nSummarize the following conversation.\n\n{dialogue}\n\n\n    \"\"\"\n\n    # Input constructed prompt instead of the dialogue.\n    inputs = tokenizer(prompt, return_tensors='pt')\n    output = tokenizer.decode(\n        model.generate(\n            inputs[\"input_ids\"], \n            max_new_tokens=50,\n        )[0], \n        skip_special_tokens=True\n    )\n    \n    print(dash_line)\n    print('Example ', i + 1)\n    print(dash_line)\n    print(f'INPUT PROMPT:\\n{prompt}')\n    print(dash_line)\n    print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n    print(dash_line)    \n    print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:40:59.712585Z","iopub.execute_input":"2023-08-05T17:40:59.712965Z","iopub.status.idle":"2023-08-05T17:41:02.402255Z","shell.execute_reply.started":"2023-08-05T17:40:59.712933Z","shell.execute_reply":"2023-08-05T17:41:02.400916Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nExample  1\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n\nSummarize the following conversation.\n\n#Person1#: What time is it, Tom?\n#Person2#: Just a minute. It's ten to nine by my watch.\n#Person1#: Is it? I had no idea it was so late. I must be off now.\n#Person2#: What's the hurry?\n#Person1#: I must catch the nine-thirty train.\n#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n\n\n    \n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\n#Person1#: It's ten to nine.\n\n---------------------------------------------------------------------------------------------------\nExample  2\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n\nSummarize the following conversation.\n\n#Person1#: Have you considered upgrading your system?\n#Person2#: Yes, but I'm not sure what exactly I would need.\n#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n#Person2#: That would be a definite bonus.\n#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n#Person2#: How can we do that?\n#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n#Person2#: No.\n#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n#Person2#: That sounds great. Thanks.\n\n\n    \n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\n#Person1#: I'm thinking of upgrading my computer.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Solving the above mentioned exercise - second point**\n- Try to rephrase the beginning of the `prompt` text from `Summarize the following conversation.` to something different - and see how it will influence the generated output.\n\n**Observations after soving execrcise for First Point**\n- Changing the prompts gives different summaries. For example 2, sometimes it did not properly summarize. For prompt related to providing email subject; it looks very accurately giving email subjects in 2 words, I am impressed here.\n","metadata":{}},{"cell_type":"code","source":"for i, index in enumerate(example_indices):\n    dialogue = dataset['test'][index]['dialogue']\n    summary = dataset['test'][index]['summary']\n\n    prompt = f\"\"\"\nGet the summary out of below coversation.\n\n{dialogue}\n\nSummary:\n    \"\"\"\n\n    # Input constructed prompt instead of the dialogue.\n    inputs = tokenizer(prompt, return_tensors='pt')\n    output = tokenizer.decode(\n        model.generate(\n            inputs[\"input_ids\"], \n            max_new_tokens=50,\n        )[0], \n        skip_special_tokens=True\n    )\n    \n    print(dash_line)\n    print('Example ', i + 1)\n    print(dash_line)\n    print(f'INPUT PROMPT:\\n{prompt}')\n    print(dash_line)\n    print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n    print(dash_line)    \n    print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:41:02.404222Z","iopub.execute_input":"2023-08-05T17:41:02.405089Z","iopub.status.idle":"2023-08-05T17:41:06.818910Z","shell.execute_reply.started":"2023-08-05T17:41:02.405040Z","shell.execute_reply":"2023-08-05T17:41:06.817419Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nExample  1\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n\nGet the summary out of below coversation.\n\n#Person1#: What time is it, Tom?\n#Person2#: Just a minute. It's ten to nine by my watch.\n#Person1#: Is it? I had no idea it was so late. I must be off now.\n#Person2#: What's the hurry?\n#Person1#: I must catch the nine-thirty train.\n#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n\nSummary:\n    \n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\nTom is late for the train.\n\n---------------------------------------------------------------------------------------------------\nExample  2\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n\nGet the summary out of below coversation.\n\n#Person1#: Have you considered upgrading your system?\n#Person2#: Yes, but I'm not sure what exactly I would need.\n#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n#Person2#: That would be a definite bonus.\n#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n#Person2#: How can we do that?\n#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n#Person2#: No.\n#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n#Person2#: That sounds great. Thanks.\n\nSummary:\n    \n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\n#Person1#: Have you considered upgrading your system? #Person2#: Yes, but I'm not sure what exactly I would need. #Person1#: You could consider adding a painting program to your software\n\n","output_type":"stream"}]},{"cell_type":"code","source":"for i, index in enumerate(example_indices):\n    dialogue = dataset['test'][index]['dialogue']\n    summary = dataset['test'][index]['summary']\n\n    prompt = f\"\"\"\nBrief me the conversation in one line please\n\n{dialogue}\n\nSummary:\n    \"\"\"\n\n    # Input constructed prompt instead of the dialogue.\n    inputs = tokenizer(prompt, return_tensors='pt')\n    output = tokenizer.decode(\n        model.generate(\n            inputs[\"input_ids\"], \n            max_new_tokens=50,\n        )[0], \n        skip_special_tokens=True\n    )\n    \n    print(dash_line)\n    print('Example ', i + 1)\n    print(dash_line)\n    print(f'INPUT PROMPT:\\n{prompt}')\n    print(dash_line)\n    print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n    print(dash_line)    \n    print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:41:06.826983Z","iopub.execute_input":"2023-08-05T17:41:06.827508Z","iopub.status.idle":"2023-08-05T17:41:11.154450Z","shell.execute_reply.started":"2023-08-05T17:41:06.827469Z","shell.execute_reply":"2023-08-05T17:41:11.152977Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nExample  1\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n\nBrief me the conversation in one line please\n\n#Person1#: What time is it, Tom?\n#Person2#: Just a minute. It's ten to nine by my watch.\n#Person1#: Is it? I had no idea it was so late. I must be off now.\n#Person2#: What's the hurry?\n#Person1#: I must catch the nine-thirty train.\n#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n\nSummary:\n    \n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\nThe train is about to leave.\n\n---------------------------------------------------------------------------------------------------\nExample  2\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n\nBrief me the conversation in one line please\n\n#Person1#: Have you considered upgrading your system?\n#Person2#: Yes, but I'm not sure what exactly I would need.\n#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n#Person2#: That would be a definite bonus.\n#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n#Person2#: How can we do that?\n#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n#Person2#: No.\n#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n#Person2#: That sounds great. Thanks.\n\nSummary:\n    \n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\n#Person1#: I'm thinking of upgrading my computer. #Person2#: I'm not sure what exactly I would need. #Person1#: I'd probably need a painting program. #P\n\n","output_type":"stream"}]},{"cell_type":"code","source":"for i, index in enumerate(example_indices):\n    dialogue = dataset['test'][index]['dialogue']\n    summary = dataset['test'][index]['summary']\n\n    prompt = f\"\"\"\nPlease share two liner summary of the chat\n\n{dialogue}\n\nSummary:\n    \"\"\"\n\n    # Input constructed prompt instead of the dialogue.\n    inputs = tokenizer(prompt, return_tensors='pt')\n    output = tokenizer.decode(\n        model.generate(\n            inputs[\"input_ids\"], \n            max_new_tokens=50,\n        )[0], \n        skip_special_tokens=True\n    )\n    \n    print(dash_line)\n    print('Example ', i + 1)\n    print(dash_line)\n    print(f'INPUT PROMPT:\\n{prompt}')\n    print(dash_line)\n    print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n    print(dash_line)    \n    print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:41:11.156639Z","iopub.execute_input":"2023-08-05T17:41:11.157118Z","iopub.status.idle":"2023-08-05T17:41:15.604782Z","shell.execute_reply.started":"2023-08-05T17:41:11.157072Z","shell.execute_reply":"2023-08-05T17:41:15.603269Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nExample  1\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n\nPlease share two liner summary of the chat\n\n#Person1#: What time is it, Tom?\n#Person2#: Just a minute. It's ten to nine by my watch.\n#Person1#: Is it? I had no idea it was so late. I must be off now.\n#Person2#: What's the hurry?\n#Person1#: I must catch the nine-thirty train.\n#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n\nSummary:\n    \n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\nThe train is about to start.\n\n---------------------------------------------------------------------------------------------------\nExample  2\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n\nPlease share two liner summary of the chat\n\n#Person1#: Have you considered upgrading your system?\n#Person2#: Yes, but I'm not sure what exactly I would need.\n#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n#Person2#: That would be a definite bonus.\n#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n#Person2#: How can we do that?\n#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n#Person2#: No.\n#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n#Person2#: That sounds great. Thanks.\n\nSummary:\n    \n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\n#Person1: Have you considered upgrading your system? #Person2: Yes, but I'm not sure what exactly I would need. #Person1: You could consider adding a painting program to your software. #P\n\n","output_type":"stream"}]},{"cell_type":"code","source":"for i, index in enumerate(example_indices):\n    dialogue = dataset['test'][index]['dialogue']\n    summary = dataset['test'][index]['summary']\n\n    prompt = f\"\"\"\nProvide me the subject of the chatting\n\n{dialogue}\n\nSummary:\n    \"\"\"\n\n    # Input constructed prompt instead of the dialogue.\n    inputs = tokenizer(prompt, return_tensors='pt')\n    output = tokenizer.decode(\n        model.generate(\n            inputs[\"input_ids\"], \n            max_new_tokens=50,\n        )[0], \n        skip_special_tokens=True\n    )\n    \n    print(dash_line)\n    print('Example ', i + 1)\n    print(dash_line)\n    print(f'INPUT PROMPT:\\n{prompt}')\n    print(dash_line)\n    print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n    print(dash_line)    \n    print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:41:15.606758Z","iopub.execute_input":"2023-08-05T17:41:15.607141Z","iopub.status.idle":"2023-08-05T17:41:17.839317Z","shell.execute_reply.started":"2023-08-05T17:41:15.607108Z","shell.execute_reply":"2023-08-05T17:41:17.837922Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nExample  1\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n\nProvide me the subject of the chatting\n\n#Person1#: What time is it, Tom?\n#Person2#: Just a minute. It's ten to nine by my watch.\n#Person1#: Is it? I had no idea it was so late. I must be off now.\n#Person2#: What's the hurry?\n#Person1#: I must catch the nine-thirty train.\n#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n\nSummary:\n    \n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\nThe train is about to leave.\n\n---------------------------------------------------------------------------------------------------\nExample  2\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n\nProvide me the subject of the chatting\n\n#Person1#: Have you considered upgrading your system?\n#Person2#: Yes, but I'm not sure what exactly I would need.\n#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n#Person2#: That would be a definite bonus.\n#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n#Person2#: How can we do that?\n#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n#Person2#: No.\n#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n#Person2#: That sounds great. Thanks.\n\nSummary:\n    \n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\n#Person1#: I'm considering upgrading my system.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"for i, index in enumerate(example_indices):\n    dialogue = dataset['test'][index]['dialogue']\n    summary = dataset['test'][index]['summary']\n\n    prompt = f\"\"\"\nProvide me the email subject for the conversation\n\n{dialogue}\n\nSummary:\n    \"\"\"\n\n    # Input constructed prompt instead of the dialogue.\n    inputs = tokenizer(prompt, return_tensors='pt')\n    output = tokenizer.decode(\n        model.generate(\n            inputs[\"input_ids\"], \n            max_new_tokens=50,\n        )[0], \n        skip_special_tokens=True\n    )\n    \n    print(dash_line)\n    print('Example ', i + 1)\n    print(dash_line)\n    print(f'INPUT PROMPT:\\n{prompt}')\n    print(dash_line)\n    print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n    print(dash_line)    \n    print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:41:17.841238Z","iopub.execute_input":"2023-08-05T17:41:17.841790Z","iopub.status.idle":"2023-08-05T17:41:19.098354Z","shell.execute_reply.started":"2023-08-05T17:41:17.841744Z","shell.execute_reply":"2023-08-05T17:41:19.096912Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nExample  1\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n\nProvide me the email subject for the conversation\n\n#Person1#: What time is it, Tom?\n#Person2#: Just a minute. It's ten to nine by my watch.\n#Person1#: Is it? I had no idea it was so late. I must be off now.\n#Person2#: What's the hurry?\n#Person1#: I must catch the nine-thirty train.\n#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n\nSummary:\n    \n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\nThe train\n\n---------------------------------------------------------------------------------------------------\nExample  2\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n\nProvide me the email subject for the conversation\n\n#Person1#: Have you considered upgrading your system?\n#Person2#: Yes, but I'm not sure what exactly I would need.\n#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n#Person2#: That would be a definite bonus.\n#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n#Person2#: How can we do that?\n#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n#Person2#: No.\n#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n#Person2#: That sounds great. Thanks.\n\nSummary:\n    \n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\nComputer upgrades\n\n","output_type":"stream"}]},{"cell_type":"code","source":"for i, index in enumerate(example_indices):\n    dialogue = dataset['test'][index]['dialogue']\n    summary = dataset['test'][index]['summary']\n\n    prompt = f\"\"\"\nSummarize the sentiments of the conversation\n\n{dialogue}\n\nSummary:\n    \"\"\"\n\n    # Input constructed prompt instead of the dialogue.\n    inputs = tokenizer(prompt, return_tensors='pt')\n    output = tokenizer.decode(\n        model.generate(\n            inputs[\"input_ids\"], \n            max_new_tokens=50,\n        )[0], \n        skip_special_tokens=True\n    )\n    \n    print(dash_line)\n    print('Example ', i + 1)\n    print(dash_line)\n    print(f'INPUT PROMPT:\\n{prompt}')\n    print(dash_line)\n    print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n    print(dash_line)    \n    print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:41:19.100546Z","iopub.execute_input":"2023-08-05T17:41:19.100992Z","iopub.status.idle":"2023-08-05T17:41:23.977231Z","shell.execute_reply.started":"2023-08-05T17:41:19.100946Z","shell.execute_reply":"2023-08-05T17:41:23.975948Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nExample  1\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n\nSummarize the sentiments of the conversation\n\n#Person1#: What time is it, Tom?\n#Person2#: Just a minute. It's ten to nine by my watch.\n#Person1#: Is it? I had no idea it was so late. I must be off now.\n#Person2#: What's the hurry?\n#Person1#: I must catch the nine-thirty train.\n#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n\nSummary:\n    \n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\nThe train is about to leave, but Tom is still late.\n\n---------------------------------------------------------------------------------------------------\nExample  2\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n\nSummarize the sentiments of the conversation\n\n#Person1#: Have you considered upgrading your system?\n#Person2#: Yes, but I'm not sure what exactly I would need.\n#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n#Person2#: That would be a definite bonus.\n#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n#Person2#: How can we do that?\n#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n#Person2#: No.\n#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n#Person2#: That sounds great. Thanks.\n\nSummary:\n    \n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\n#Person1: I'm thinking about upgrading my computer. #Person2: I'm not sure what exactly I would need. #Person1: I'd probably need a painting program. #Person2:\n\n","output_type":"stream"}]},{"cell_type":"code","source":"for i, index in enumerate(example_indices):\n    dialogue = dataset['test'][index]['dialogue']\n    summary = dataset['test'][index]['summary']\n\n    prompt = f\"\"\"\nwhat are their emotions while chatting?\n\n{dialogue}\n\nSummary:\n    \"\"\"\n\n    # Input constructed prompt instead of the dialogue.\n    inputs = tokenizer(prompt, return_tensors='pt')\n    output = tokenizer.decode(\n        model.generate(\n            inputs[\"input_ids\"], \n            max_new_tokens=50,\n        )[0], \n        skip_special_tokens=True\n    )\n    \n    print(dash_line)\n    print('Example ', i + 1)\n    print(dash_line)\n    print(f'INPUT PROMPT:\\n{prompt}')\n    print(dash_line)\n    print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n    print(dash_line)    \n    print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:41:23.979069Z","iopub.execute_input":"2023-08-05T17:41:23.980347Z","iopub.status.idle":"2023-08-05T17:41:28.715717Z","shell.execute_reply.started":"2023-08-05T17:41:23.980279Z","shell.execute_reply":"2023-08-05T17:41:28.714533Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nExample  1\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n\nwhat are their emotions while chatting?\n\n#Person1#: What time is it, Tom?\n#Person2#: Just a minute. It's ten to nine by my watch.\n#Person1#: Is it? I had no idea it was so late. I must be off now.\n#Person2#: What's the hurry?\n#Person1#: I must catch the nine-thirty train.\n#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n\nSummary:\n    \n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\nThe people are chatting about the time.\n\n---------------------------------------------------------------------------------------------------\nExample  2\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n\nwhat are their emotions while chatting?\n\n#Person1#: Have you considered upgrading your system?\n#Person2#: Yes, but I'm not sure what exactly I would need.\n#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n#Person2#: That would be a definite bonus.\n#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n#Person2#: How can we do that?\n#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n#Person2#: No.\n#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n#Person2#: That sounds great. Thanks.\n\nSummary:\n    \n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\n#Person1: Have you considered upgrading your system? #Person2: Yes, but I'm not sure what exactly I would need. #Person1: You could consider adding a painting program to your software. #P\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<a name='3.2'></a>\n### 3.2 - Zero Shot Inference with the Prompt Template from FLAN-T5\n\nLet's use a slightly different prompt. FLAN-T5 has many prompt templates that are published for certain tasks [here](https://github.com/google-research/FLAN/tree/main/flan/v2). In the following code, you will use one of the [pre-built FLAN-T5 prompts](https://github.com/google-research/FLAN/blob/main/flan/v2/templates.py):","metadata":{}},{"cell_type":"code","source":"for i, index in enumerate(example_indices):\n    dialogue = dataset['test'][index]['dialogue']\n    summary = dataset['test'][index]['summary']\n        \n    prompt = f\"\"\"\nDialogue:\n\n{dialogue}\n\nWhat was going on?\n\"\"\"\n\n    inputs = tokenizer(prompt, return_tensors='pt')\n    output = tokenizer.decode(\n        model.generate(\n            inputs[\"input_ids\"], \n            max_new_tokens=50,\n        )[0], \n        skip_special_tokens=True\n    )\n\n    print(dash_line)\n    print('Example ', i + 1)\n    print(dash_line)\n    print(f'INPUT PROMPT:\\n{prompt}')\n    print(dash_line)\n    print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n    print(dash_line)\n    print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:41:28.717314Z","iopub.execute_input":"2023-08-05T17:41:28.717724Z","iopub.status.idle":"2023-08-05T17:41:33.071011Z","shell.execute_reply.started":"2023-08-05T17:41:28.717690Z","shell.execute_reply":"2023-08-05T17:41:33.069591Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nExample  1\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n\nDialogue:\n\n#Person1#: What time is it, Tom?\n#Person2#: Just a minute. It's ten to nine by my watch.\n#Person1#: Is it? I had no idea it was so late. I must be off now.\n#Person2#: What's the hurry?\n#Person1#: I must catch the nine-thirty train.\n#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n\nWhat was going on?\n\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\nTom is late for the train.\n\n---------------------------------------------------------------------------------------------------\nExample  2\n---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\n\nDialogue:\n\n#Person1#: Have you considered upgrading your system?\n#Person2#: Yes, but I'm not sure what exactly I would need.\n#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n#Person2#: That would be a definite bonus.\n#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n#Person2#: How can we do that?\n#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n#Person2#: No.\n#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n#Person2#: That sounds great. Thanks.\n\nWhat was going on?\n\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\n#Person1#: You could add a painting program to your software. #Person2#: That would be a bonus. #Person1#: You might also want to upgrade your hardware. #Person1#\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Notice that this prompt from FLAN-T5 did help a bit, but still struggles to pick up on the nuance of the conversation. This is what you will try to solve with the few shot inferencing.","metadata":{}},{"cell_type":"markdown","source":"<a name='4'></a>\n## 4 - Summarize Dialogue with One Shot and Few Shot Inference\n\n**One shot and few shot inference** are the practices of providing an LLM with either one or more full examples of prompt-response pairs that match your task - before your actual prompt that you want completed. This is called \"in-context learning\" and puts your model into a state that understands your specific task.  You can read more about it in [this blog from HuggingFace](https://huggingface.co/blog/few-shot-learning-gpt-neo-and-inference-api).","metadata":{}},{"cell_type":"markdown","source":"<a name='4.1'></a>\n### 4.1 - One Shot Inference\n\nLet's build a function that takes a list of `example_indices_full`, generates a prompt with full examples, then at the end appends the prompt which you want the model to complete (`example_index_to_summarize`).  You will use the same FLAN-T5 prompt template from section [3.2](#3.2). ","metadata":{"tags":[]}},{"cell_type":"code","source":"def make_prompt(example_indices_full, example_index_to_summarize):\n    prompt = ''\n    for index in example_indices_full:\n        dialogue = dataset['test'][index]['dialogue']\n        summary = dataset['test'][index]['summary']\n        \n        # The stop sequence '{summary}\\n\\n\\n' is important for FLAN-T5. Other models may have their own preferred stop sequence.\n        prompt += f\"\"\"\nDialogue:\n\n{dialogue}\n\nWhat was going on?\n{summary}\n\n\n\"\"\"\n    \n    dialogue = dataset['test'][example_index_to_summarize]['dialogue']\n    \n    prompt += f\"\"\"\nDialogue:\n\n{dialogue}\n\nWhat was going on?\n\"\"\"\n        \n    return prompt","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:41:33.073239Z","iopub.execute_input":"2023-08-05T17:41:33.074226Z","iopub.status.idle":"2023-08-05T17:41:33.086937Z","shell.execute_reply.started":"2023-08-05T17:41:33.074173Z","shell.execute_reply":"2023-08-05T17:41:33.085782Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"Construct the prompt to perform one shot inference:","metadata":{"tags":[]}},{"cell_type":"code","source":"example_indices_full = [40]\nexample_index_to_summarize = 200\n\none_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n\nprint(one_shot_prompt)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:41:33.089178Z","iopub.execute_input":"2023-08-05T17:41:33.090466Z","iopub.status.idle":"2023-08-05T17:41:33.103312Z","shell.execute_reply.started":"2023-08-05T17:41:33.090411Z","shell.execute_reply":"2023-08-05T17:41:33.102414Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"\nDialogue:\n\n#Person1#: What time is it, Tom?\n#Person2#: Just a minute. It's ten to nine by my watch.\n#Person1#: Is it? I had no idea it was so late. I must be off now.\n#Person2#: What's the hurry?\n#Person1#: I must catch the nine-thirty train.\n#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n\nWhat was going on?\n#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n\n\n\nDialogue:\n\n#Person1#: Have you considered upgrading your system?\n#Person2#: Yes, but I'm not sure what exactly I would need.\n#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n#Person2#: That would be a definite bonus.\n#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n#Person2#: How can we do that?\n#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n#Person2#: No.\n#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n#Person2#: That sounds great. Thanks.\n\nWhat was going on?\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now pass this prompt to perform the one shot inference:","metadata":{"tags":[]}},{"cell_type":"code","source":"summary = dataset['test'][example_index_to_summarize]['summary']\n\ninputs = tokenizer(one_shot_prompt, return_tensors='pt')\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        max_new_tokens=50,\n    )[0], \n    skip_special_tokens=True\n)\n\nprint(dash_line)\nprint(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\nprint(dash_line)\nprint(f'MODEL GENERATION - ONE SHOT:\\n{output}')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:41:33.104967Z","iopub.execute_input":"2023-08-05T17:41:33.105372Z","iopub.status.idle":"2023-08-05T17:41:36.618966Z","shell.execute_reply.started":"2023-08-05T17:41:33.105313Z","shell.execute_reply":"2023-08-05T17:41:36.617440Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ONE SHOT:\n#Person1 wants to upgrade his system. #Person2 wants to add a painting program to his software. #Person1 wants to add a CD-ROM drive.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<a name='4.2'></a>\n### 4.2 - Few Shot Inference\n\nLet's explore few shot inference by adding two more full dialogue-summary pairs to your prompt.","metadata":{"tags":[]}},{"cell_type":"code","source":"example_indices_full = [40, 80, 120]\nexample_index_to_summarize = 200\n\nfew_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n\nprint(few_shot_prompt)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:41:36.620611Z","iopub.execute_input":"2023-08-05T17:41:36.621311Z","iopub.status.idle":"2023-08-05T17:41:36.630618Z","shell.execute_reply.started":"2023-08-05T17:41:36.621268Z","shell.execute_reply":"2023-08-05T17:41:36.628867Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"\nDialogue:\n\n#Person1#: What time is it, Tom?\n#Person2#: Just a minute. It's ten to nine by my watch.\n#Person1#: Is it? I had no idea it was so late. I must be off now.\n#Person2#: What's the hurry?\n#Person1#: I must catch the nine-thirty train.\n#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n\nWhat was going on?\n#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n\n\n\nDialogue:\n\n#Person1#: May, do you mind helping me prepare for the picnic?\n#Person2#: Sure. Have you checked the weather report?\n#Person1#: Yes. It says it will be sunny all day. No sign of rain at all. This is your father's favorite sausage. Sandwiches for you and Daniel.\n#Person2#: No, thanks Mom. I'd like some toast and chicken wings.\n#Person1#: Okay. Please take some fruit salad and crackers for me.\n#Person2#: Done. Oh, don't forget to take napkins disposable plates, cups and picnic blanket.\n#Person1#: All set. May, can you help me take all these things to the living room?\n#Person2#: Yes, madam.\n#Person1#: Ask Daniel to give you a hand?\n#Person2#: No, mom, I can manage it by myself. His help just causes more trouble.\n\nWhat was going on?\nMom asks May to help to prepare for the picnic and May agrees.\n\n\n\nDialogue:\n\n#Person1#: Hello, I bought the pendant in your shop, just before. \n#Person2#: Yes. Thank you very much. \n#Person1#: Now I come back to the hotel and try to show it to my friend, the pendant is broken, I'm afraid. \n#Person2#: Oh, is it? \n#Person1#: Would you change it to a new one? \n#Person2#: Yes, certainly. You have the receipt? \n#Person1#: Yes, I do. \n#Person2#: Then would you kindly come to our shop with the receipt by 10 o'clock? We will replace it. \n#Person1#: Thank you so much. \n\nWhat was going on?\n#Person1# wants to change the broken pendant in #Person2#'s shop.\n\n\n\nDialogue:\n\n#Person1#: Have you considered upgrading your system?\n#Person2#: Yes, but I'm not sure what exactly I would need.\n#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n#Person2#: That would be a definite bonus.\n#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n#Person2#: How can we do that?\n#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n#Person2#: No.\n#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n#Person2#: That sounds great. Thanks.\n\nWhat was going on?\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now pass this prompt to perform a few shot inference:","metadata":{"tags":[]}},{"cell_type":"code","source":"summary = dataset['test'][example_index_to_summarize]['summary']\n\ninputs = tokenizer(few_shot_prompt, return_tensors='pt')\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        max_new_tokens=50,\n    )[0], \n    skip_special_tokens=True\n)\n\nprint(dash_line)\nprint(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\nprint(dash_line)\nprint(f'MODEL GENERATION - FEW SHOT:\\n{output}')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:41:36.632582Z","iopub.execute_input":"2023-08-05T17:41:36.633241Z","iopub.status.idle":"2023-08-05T17:41:41.788161Z","shell.execute_reply.started":"2023-08-05T17:41:36.633208Z","shell.execute_reply":"2023-08-05T17:41:41.786939Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (819 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - FEW SHOT:\n#Person1 wants to upgrade his system. #Person2 wants to add a painting program to his software. #Person1 wants to upgrade his hardware.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"In this case, few shot did not provide much of an improvement over one shot inference.  And, anything above 5 or 6 shot will typically not help much, either.  Also, you need to make sure that you do not exceed the model's input-context length which, in our case, if 512 tokens.  Anything above the context length will be ignored.\n\nHowever, you can see that feeding in at least one full example (one shot) provides the model with more information and qualitatively improves the summary overall.","metadata":{"tags":[]}},{"cell_type":"markdown","source":"**Exercise:**\n\nExperiment with the few shot inferencing.\n- Choose different dialogues - change the indices in the `example_indices_full` list and `example_index_to_summarize` value.\n- Change the number of shots. Be sure to stay within the model's 512 context length, however.\n\nHow well does few shot inferencing work with other examples?","metadata":{"tags":[]}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Exercise Performed Below:**\n\nExperiment with the few shot inferencing.\n- Choose different dialogues - change the indices in the `example_indices_full` list and `example_index_to_summarize` value.\n- Change the number of shots. Be sure to stay within the model's 512 context length, however.\n\nHow well does few shot inferencing work with other examples?","metadata":{"tags":[]}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observation after performing above mentioned exercise**\n- In both of the cases below, model sometimes summarizes well and sometimes not.","metadata":{"tags":[]}},{"cell_type":"markdown","source":"#### Changing the indices in the `example_indices_full` list and `example_index_to_summarize` value.","metadata":{}},{"cell_type":"code","source":"example_indices_full = [50, 80, 120]\nexample_index_to_summarize = 200\n\nfew_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n\nprint(few_shot_prompt)\n\nsummary = dataset['test'][example_index_to_summarize]['summary']\n\ninputs = tokenizer(few_shot_prompt, return_tensors='pt')\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        max_new_tokens=50,\n    )[0], \n    skip_special_tokens=True\n)\n\nprint(dash_line)\nprint(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\nprint(dash_line)\nprint(f'MODEL GENERATION - FEW SHOT:\\n{output}')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:41:41.789517Z","iopub.execute_input":"2023-08-05T17:41:41.789863Z","iopub.status.idle":"2023-08-05T17:41:45.506632Z","shell.execute_reply.started":"2023-08-05T17:41:41.789833Z","shell.execute_reply":"2023-08-05T17:41:45.505275Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"\nDialogue:\n\n#Person1#: Yeah. Just pull on this strip. Then peel off the back.\n#Person2#: You might make a few enemies this way.\n#Person1#: If they don't think this is fun, they're not meant to be our friends.\n#Person2#: You mean your friends. I think it's cruel.\n#Person1#: Yeah. But it's fun. Look at those two ugly old ladies. . . or are they men?\n#Person2#: Hurry! Get a shot!. . . Hand it over!\n#Person1#: I knew you'd come around. . .\n\nWhat was going on?\n#Person1# is about to make a prank. #Person2# thinks it's cruel at first but then joins.\n\n\n\nDialogue:\n\n#Person1#: May, do you mind helping me prepare for the picnic?\n#Person2#: Sure. Have you checked the weather report?\n#Person1#: Yes. It says it will be sunny all day. No sign of rain at all. This is your father's favorite sausage. Sandwiches for you and Daniel.\n#Person2#: No, thanks Mom. I'd like some toast and chicken wings.\n#Person1#: Okay. Please take some fruit salad and crackers for me.\n#Person2#: Done. Oh, don't forget to take napkins disposable plates, cups and picnic blanket.\n#Person1#: All set. May, can you help me take all these things to the living room?\n#Person2#: Yes, madam.\n#Person1#: Ask Daniel to give you a hand?\n#Person2#: No, mom, I can manage it by myself. His help just causes more trouble.\n\nWhat was going on?\nMom asks May to help to prepare for the picnic and May agrees.\n\n\n\nDialogue:\n\n#Person1#: Hello, I bought the pendant in your shop, just before. \n#Person2#: Yes. Thank you very much. \n#Person1#: Now I come back to the hotel and try to show it to my friend, the pendant is broken, I'm afraid. \n#Person2#: Oh, is it? \n#Person1#: Would you change it to a new one? \n#Person2#: Yes, certainly. You have the receipt? \n#Person1#: Yes, I do. \n#Person2#: Then would you kindly come to our shop with the receipt by 10 o'clock? We will replace it. \n#Person1#: Thank you so much. \n\nWhat was going on?\n#Person1# wants to change the broken pendant in #Person2#'s shop.\n\n\n\nDialogue:\n\n#Person1#: Have you considered upgrading your system?\n#Person2#: Yes, but I'm not sure what exactly I would need.\n#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n#Person2#: That would be a definite bonus.\n#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n#Person2#: How can we do that?\n#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n#Person2#: No.\n#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n#Person2#: That sounds great. Thanks.\n\nWhat was going on?\n\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - FEW SHOT:\n#Person1 wants to upgrade his system and hardware.\n","output_type":"stream"}]},{"cell_type":"code","source":"example_indices_full = [52, 82, 120]\nexample_index_to_summarize = 200\n\nfew_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n\nprint(few_shot_prompt)\n\nsummary = dataset['test'][example_index_to_summarize]['summary']\n\ninputs = tokenizer(few_shot_prompt, return_tensors='pt')\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        max_new_tokens=50,\n    )[0], \n    skip_special_tokens=True\n)\n\nprint(dash_line)\nprint(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\nprint(dash_line)\nprint(f'MODEL GENERATION - FEW SHOT:\\n{output}')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:41:45.508496Z","iopub.execute_input":"2023-08-05T17:41:45.512080Z","iopub.status.idle":"2023-08-05T17:41:50.931191Z","shell.execute_reply.started":"2023-08-05T17:41:45.512034Z","shell.execute_reply":"2023-08-05T17:41:50.929608Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"\nDialogue:\n\n#Person1#: What does your sister look like, Mike?\n#Person2#: Well, she's tall and pretty.\n#Person1#: Is she like you?\n#Person2#: I suppose so. We're both friendly and easy-going.\n#Person1#: Is she as clever as you?\n#Person2#: No, she's not as clever as me.\n#Person1#: Big head!\n\nWhat was going on?\nMike describes to #Person1# his sister's characters and personality.\n\n\n\nDialogue:\n\n#Person1#: Hello, are you Muriel Douglas?\n#Person2#: Yes, and you must be James. It's nice to meet you at long last.\n#Person1#: Yes, you too. Thanks for agreeing to meet with us about the new account. My associate, Susan Kim, should be here any minute. Would you like something to drink while we're waiting?\n#Person2#: No, thanks. I'm fine. Did you have a nice holiday?\n#Person1#: Yes, I did. My family and I went to Tahoe to ski and the weather was great. How about you?\n#Person2#: I stayed in L. A. and it was sunny the entire weekend. We spent most of the time at home but we did go see King Kong on Christmas day.\n#Person1#: How did you like it?\n#Person2#: It was better than I expected. But, you know, I think I would have enjoyed skiing in Tahoe even better. Do you go there often?\n#Person1#: No, not much. My wife doesn't like to ski. She prefers vacationing where it's warmer, like Hawaii.\n#Person2#: I don't blame her. I really enjoyed it there when we went a few years ago. I'd like to go back sometime soon.\n#Person1#: Yes, me too. Oh, here's Susan now. Let me introduce you.\n\nWhat was going on?\nJames and Muriel are talking while waiting for Susan, Muriel's associate. They talk about how they spent the holiday with their families.\n\n\n\nDialogue:\n\n#Person1#: Hello, I bought the pendant in your shop, just before. \n#Person2#: Yes. Thank you very much. \n#Person1#: Now I come back to the hotel and try to show it to my friend, the pendant is broken, I'm afraid. \n#Person2#: Oh, is it? \n#Person1#: Would you change it to a new one? \n#Person2#: Yes, certainly. You have the receipt? \n#Person1#: Yes, I do. \n#Person2#: Then would you kindly come to our shop with the receipt by 10 o'clock? We will replace it. \n#Person1#: Thank you so much. \n\nWhat was going on?\n#Person1# wants to change the broken pendant in #Person2#'s shop.\n\n\n\nDialogue:\n\n#Person1#: Have you considered upgrading your system?\n#Person2#: Yes, but I'm not sure what exactly I would need.\n#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n#Person2#: That would be a definite bonus.\n#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n#Person2#: How can we do that?\n#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n#Person2#: No.\n#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n#Person2#: That sounds great. Thanks.\n\nWhat was going on?\n\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - FEW SHOT:\n#Person1 wants to upgrade his system. #Person2 wants to add a painting program to his software. #Person1 wants to upgrade his hardware.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Changing the number of shots","metadata":{}},{"cell_type":"code","source":"example_indices_full = [10, 20, 30, 120]\nexample_index_to_summarize = 200\n\nfew_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n\nprint(few_shot_prompt)\n\nsummary = dataset['test'][example_index_to_summarize]['summary']\n\ninputs = tokenizer(few_shot_prompt, return_tensors='pt')\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        max_new_tokens=50,\n    )[0], \n    skip_special_tokens=True\n)\n\nprint(dash_line)\nprint(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\nprint(dash_line)\nprint(f'MODEL GENERATION - FEW SHOT:\\n{output}')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:41:50.933460Z","iopub.execute_input":"2023-08-05T17:41:50.933934Z","iopub.status.idle":"2023-08-05T17:41:58.495090Z","shell.execute_reply.started":"2023-08-05T17:41:50.933887Z","shell.execute_reply":"2023-08-05T17:41:58.493591Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"\nDialogue:\n\n#Person1#: Happy Birthday, this is for you, Brian.\n#Person2#: I'm so happy you remember, please come in and enjoy the party. Everyone's here, I'm sure you have a good time.\n#Person1#: Brian, may I have a pleasure to have a dance with you?\n#Person2#: Ok.\n#Person1#: This is really wonderful party.\n#Person2#: Yes, you are always popular with everyone. and you look very pretty today.\n#Person1#: Thanks, that's very kind of you to say. I hope my necklace goes with my dress, and they both make me look good I feel.\n#Person2#: You look great, you are absolutely glowing.\n#Person1#: Thanks, this is a fine party. We should have a drink together to celebrate your birthday\n\nWhat was going on?\n#Person1# attends Brian's birthday party. Brian thinks #Person1# looks great and charming.\n\n\n\nDialogue:\n\n#Person1#: What's wrong with you? Why are you scratching so much?\n#Person2#: I feel itchy! I can't stand it anymore! I think I may be coming down with something. I feel lightheaded and weak.\n#Person1#: Let me have a look. Whoa! Get away from me!\n#Person2#: What's wrong?\n#Person1#: I think you have chicken pox! You are contagious! Get away! Don't breathe on me!\n#Person2#: Maybe it's just a rash or an allergy! We can't be sure until I see a doctor.\n#Person1#: Well in the meantime you are a biohazard! I didn't get it when I was a kid and I've heard that you can even die if you get it as an adult!\n#Person2#: Are you serious? You always blow things out of proportion. In any case, I think I'll go take an oatmeal bath.\n\nWhat was going on?\n#Person1# thinks #Person2# has chicken pox and warns #Person2# about the possible hazards but #Person2# thinks it will be fine.\n\n\n\nDialogue:\n\n#Person1#: Where are you going for your trip?\n#Person2#: I think Hebei is a good place.\n#Person1#: But I heard the north of China are experiencing severe sandstorms!\n#Person2#: Really?\n#Person1#: Yes, it's said that Hebes was experiencing six degree strong winds.\n#Person2#: How do these storms affect the people who live in these areas?\n#Person1#: The report said the number of people with respiratory tract infections tended to rise after sandstorms. The sand gets into people's noses and throats and creates irritation.\n#Person2#: It sounds that sandstorms are trouble for everybody!\n#Person1#: You are quite right.\n\nWhat was going on?\n#Person2# plans to have a trip in Hebei but #Person1# says there are sandstorms in there.\n\n\n\nDialogue:\n\n#Person1#: Hello, I bought the pendant in your shop, just before. \n#Person2#: Yes. Thank you very much. \n#Person1#: Now I come back to the hotel and try to show it to my friend, the pendant is broken, I'm afraid. \n#Person2#: Oh, is it? \n#Person1#: Would you change it to a new one? \n#Person2#: Yes, certainly. You have the receipt? \n#Person1#: Yes, I do. \n#Person2#: Then would you kindly come to our shop with the receipt by 10 o'clock? We will replace it. \n#Person1#: Thank you so much. \n\nWhat was going on?\n#Person1# wants to change the broken pendant in #Person2#'s shop.\n\n\n\nDialogue:\n\n#Person1#: Have you considered upgrading your system?\n#Person2#: Yes, but I'm not sure what exactly I would need.\n#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n#Person2#: That would be a definite bonus.\n#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n#Person2#: How can we do that?\n#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n#Person2#: No.\n#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n#Person2#: That sounds great. Thanks.\n\nWhat was going on?\n\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - FEW SHOT:\n#Person1 wants to upgrade his system. #Person2 wants to add a painting program to his software. #Person1 wants to upgrade his hardware.\n","output_type":"stream"}]},{"cell_type":"code","source":"example_indices_full = [10, 20, 30, 40, 112]\nexample_index_to_summarize = 200\n\nfew_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n\nprint(few_shot_prompt)\n\nsummary = dataset['test'][example_index_to_summarize]['summary']\n\ninputs = tokenizer(few_shot_prompt, return_tensors='pt')\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        max_new_tokens=50,\n    )[0], \n    skip_special_tokens=True\n)\n\nprint(dash_line)\nprint(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\nprint(dash_line)\nprint(f'MODEL GENERATION - FEW SHOT:\\n{output}')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:41:58.497268Z","iopub.execute_input":"2023-08-05T17:41:58.498143Z","iopub.status.idle":"2023-08-05T17:42:07.451192Z","shell.execute_reply.started":"2023-08-05T17:41:58.498095Z","shell.execute_reply":"2023-08-05T17:42:07.449702Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"\nDialogue:\n\n#Person1#: Happy Birthday, this is for you, Brian.\n#Person2#: I'm so happy you remember, please come in and enjoy the party. Everyone's here, I'm sure you have a good time.\n#Person1#: Brian, may I have a pleasure to have a dance with you?\n#Person2#: Ok.\n#Person1#: This is really wonderful party.\n#Person2#: Yes, you are always popular with everyone. and you look very pretty today.\n#Person1#: Thanks, that's very kind of you to say. I hope my necklace goes with my dress, and they both make me look good I feel.\n#Person2#: You look great, you are absolutely glowing.\n#Person1#: Thanks, this is a fine party. We should have a drink together to celebrate your birthday\n\nWhat was going on?\n#Person1# attends Brian's birthday party. Brian thinks #Person1# looks great and charming.\n\n\n\nDialogue:\n\n#Person1#: What's wrong with you? Why are you scratching so much?\n#Person2#: I feel itchy! I can't stand it anymore! I think I may be coming down with something. I feel lightheaded and weak.\n#Person1#: Let me have a look. Whoa! Get away from me!\n#Person2#: What's wrong?\n#Person1#: I think you have chicken pox! You are contagious! Get away! Don't breathe on me!\n#Person2#: Maybe it's just a rash or an allergy! We can't be sure until I see a doctor.\n#Person1#: Well in the meantime you are a biohazard! I didn't get it when I was a kid and I've heard that you can even die if you get it as an adult!\n#Person2#: Are you serious? You always blow things out of proportion. In any case, I think I'll go take an oatmeal bath.\n\nWhat was going on?\n#Person1# thinks #Person2# has chicken pox and warns #Person2# about the possible hazards but #Person2# thinks it will be fine.\n\n\n\nDialogue:\n\n#Person1#: Where are you going for your trip?\n#Person2#: I think Hebei is a good place.\n#Person1#: But I heard the north of China are experiencing severe sandstorms!\n#Person2#: Really?\n#Person1#: Yes, it's said that Hebes was experiencing six degree strong winds.\n#Person2#: How do these storms affect the people who live in these areas?\n#Person1#: The report said the number of people with respiratory tract infections tended to rise after sandstorms. The sand gets into people's noses and throats and creates irritation.\n#Person2#: It sounds that sandstorms are trouble for everybody!\n#Person1#: You are quite right.\n\nWhat was going on?\n#Person2# plans to have a trip in Hebei but #Person1# says there are sandstorms in there.\n\n\n\nDialogue:\n\n#Person1#: What time is it, Tom?\n#Person2#: Just a minute. It's ten to nine by my watch.\n#Person1#: Is it? I had no idea it was so late. I must be off now.\n#Person2#: What's the hurry?\n#Person1#: I must catch the nine-thirty train.\n#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n\nWhat was going on?\n#Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n\n\n\nDialogue:\n\n#Person1#: It's partly your own fault. You should never let in anyone like that unless you're expecting him.\n#Person2#: It's all very well to say that, but someone cones to the door and says 'electricity' or 'gas' and you automatically think he is OK, especially if he shows you a card.\n\nWhat was going on?\n#Person1# blames #Person2# for letting someone in without much discretion.\n\n\n\nDialogue:\n\n#Person1#: Have you considered upgrading your system?\n#Person2#: Yes, but I'm not sure what exactly I would need.\n#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n#Person2#: That would be a definite bonus.\n#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n#Person2#: How can we do that?\n#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n#Person2#: No.\n#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n#Person2#: That sounds great. Thanks.\n\nWhat was going on?\n\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - FEW SHOT:\n#Person1 wants to upgrade his system. #Person2 wants to add a painting program to his software. #Person1 wants to upgrade his hardware.\n","output_type":"stream"}]},{"cell_type":"code","source":"example_indices_full = [10, 110]\nexample_index_to_summarize = 200\n\nfew_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n\nprint(few_shot_prompt)\n\nsummary = dataset['test'][example_index_to_summarize]['summary']\n\ninputs = tokenizer(few_shot_prompt, return_tensors='pt')\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        max_new_tokens=50,\n    )[0], \n    skip_special_tokens=True\n)\n\nprint(dash_line)\nprint(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\nprint(dash_line)\nprint(f'MODEL GENERATION - FEW SHOT:\\n{output}')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:42:07.453627Z","iopub.execute_input":"2023-08-05T17:42:07.454133Z","iopub.status.idle":"2023-08-05T17:42:11.502723Z","shell.execute_reply.started":"2023-08-05T17:42:07.454085Z","shell.execute_reply":"2023-08-05T17:42:11.501205Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"\nDialogue:\n\n#Person1#: Happy Birthday, this is for you, Brian.\n#Person2#: I'm so happy you remember, please come in and enjoy the party. Everyone's here, I'm sure you have a good time.\n#Person1#: Brian, may I have a pleasure to have a dance with you?\n#Person2#: Ok.\n#Person1#: This is really wonderful party.\n#Person2#: Yes, you are always popular with everyone. and you look very pretty today.\n#Person1#: Thanks, that's very kind of you to say. I hope my necklace goes with my dress, and they both make me look good I feel.\n#Person2#: You look great, you are absolutely glowing.\n#Person1#: Thanks, this is a fine party. We should have a drink together to celebrate your birthday\n\nWhat was going on?\n#Person1# attends Brian's birthday party. Brian thinks #Person1# looks great and charming.\n\n\n\nDialogue:\n\n#Person1#: Are you going to the demonstration to help stop the spread of nuclear weapons tomorrow, Cleo?\n#Person2#: No, Simon. I hate demonstrations. I have heard the police will be standing by with tear gas.\n#Person1#: Yes, but North Korea boasts it has nuclear arms.\n#Person2#: One hundred ninety countries have signed the Nuclear Non-Proliferation Treaty but the issues are just too complex. There are two sides to every story. I don't understand it and I have no intention of going to a demonstration. Demonstrations don't seem to accomplish anything anyway.\n#Person1#: Several demonstrations have changed politician's minds throughout history. As a responsible citizen I think it is important to stand up for what you believe in.\n#Person2#: Leave it to someone else. As I said, if you listen to both sides of a story, both sides have some good points. Why should I demonstrate and risk getting hurt for something that I am not even sure is right?\n#Person1#: You are not likely to get hurt. This will be a peaceful demonstration. I have spoken to the organizer for the university group. He insists that this will be peaceful. He advocates if you want world peace, peace begins at home-and that means right here in this city.\n#Person2#: You go if you want, Simon, but I plan to study for my physics exam.\n#Person1#: It would only take two hours of your day. The bus leaves the campus at 11:30 and leaves downtown to return to campus at 12:45. You could eat your lunch on the bus.\n#Person2#: I am not going, Simon. Why don't you ask the students in your political science class this afternoon if they want to go?\n#Person1#: They are all going.\n#Person2#: Okay, Simon. I need to meet my sister for coffee now.\n#Person1#: Bye then. See you in physics class tomorrow.\n\nWhat was going on?\nSimon and Cleo argue the effectiveness of demonstrations. Simon thinks they are helpful, but Cleo disagrees and refuses to go to the demonstration of helping stop the spread of nuclear weapons with Simon.\n\n\n\nDialogue:\n\n#Person1#: Have you considered upgrading your system?\n#Person2#: Yes, but I'm not sure what exactly I would need.\n#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n#Person2#: That would be a definite bonus.\n#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n#Person2#: How can we do that?\n#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n#Person2#: No.\n#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n#Person2#: That sounds great. Thanks.\n\nWhat was going on?\n\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - FEW SHOT:\nThe computer system of Person1 is outdated.\n","output_type":"stream"}]},{"cell_type":"code","source":"example_indices_full = [5, 68]\nexample_index_to_summarize = 200\n\nfew_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n\nprint(few_shot_prompt)\n\nsummary = dataset['test'][example_index_to_summarize]['summary']\n\ninputs = tokenizer(few_shot_prompt, return_tensors='pt')\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        max_new_tokens=50,\n    )[0], \n    skip_special_tokens=True\n)\n\nprint(dash_line)\nprint(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\nprint(dash_line)\nprint(f'MODEL GENERATION - FEW SHOT:\\n{output}')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:42:11.504458Z","iopub.execute_input":"2023-08-05T17:42:11.504886Z","iopub.status.idle":"2023-08-05T17:42:16.230763Z","shell.execute_reply.started":"2023-08-05T17:42:11.504850Z","shell.execute_reply":"2023-08-05T17:42:16.229311Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"\nDialogue:\n\n#Person1#: You're finally here! What took so long?\n#Person2#: I got stuck in traffic again. There was a terrible traffic jam near the Carrefour intersection.\n#Person1#: It's always rather congested down there during rush hour. Maybe you should try to find a different route to get home.\n#Person2#: I don't think it can be avoided, to be honest.\n#Person1#: perhaps it would be better if you started taking public transport system to work.\n#Person2#: I think it's something that I'll have to consider. The public transport system is pretty good.\n#Person1#: It would be better for the environment, too.\n#Person2#: I know. I feel bad about how much my car is adding to the pollution problem in this city.\n#Person1#: Taking the subway would be a lot less stressful than driving as well.\n#Person2#: The only problem is that I'm going to really miss having the freedom that you have with a car.\n#Person1#: Well, when it's nicer outside, you can start biking to work. That will give you just as much freedom as your car usually provides.\n#Person2#: That's true. I could certainly use the exercise!\n#Person1#: So, are you going to quit driving to work then?\n#Person2#: Yes, it's not good for me or for the environment.\n\nWhat was going on?\n#Person2# complains to #Person1# about the traffic jam, #Person1# suggests quitting driving and taking public transportation instead.\n\n\n\nDialogue:\n\n#Person1#: Excuse me.\n#Person2#: Yes, sir. Can I help you?\n#Person1#: Um, this steak, I asked for to be medium rare.\n#Person2#: Medium rare, that's right, sir. I remember your order.\n#Person1#: Well, I'm afraid it isn't. It's a bit too well done and rather tough. Would you mind changing?\n#Person2#: If it is not to your satisfaction, I'll certainly bring you another. But I'm afraid you may have to wait for a few minutes.\n#Person1#: Yes, that's all right. Thank you very much.\n\nWhat was going on?\n#Person1# is not satisfied with #Person1#'s steak and asks to change one, and #Person2# agrees.\n\n\n\nDialogue:\n\n#Person1#: Have you considered upgrading your system?\n#Person2#: Yes, but I'm not sure what exactly I would need.\n#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n#Person2#: That would be a definite bonus.\n#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n#Person2#: How can we do that?\n#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n#Person2#: No.\n#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n#Person2#: That sounds great. Thanks.\n\nWhat was going on?\n\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - FEW SHOT:\n#Person1 wants to upgrade his system. #Person2 wants to add a painting program to his software. #Person1 wants to upgrade his hardware.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name='5'></a>\n## 5 - Generative Configuration Parameters for Inference","metadata":{"tags":[]}},{"cell_type":"markdown","source":"You can change the configuration parameters of the `generate()` method to see a different output from the LLM. So far the only parameter that you have been setting was `max_new_tokens=50`, which defines the maximum number of tokens to generate. A full list of available parameters can be found in the [Hugging Face Generation documentation](https://huggingface.co/docs/transformers/v4.29.1/en/main_classes/text_generation#transformers.GenerationConfig). \n\nA convenient way of organizing the configuration parameters is to use `GenerationConfig` class. ","metadata":{"tags":[]}},{"cell_type":"markdown","source":"**Exercise:**\n\nChange the configuration parameters to investigate their influence on the output. \n\nPutting the parameter `do_sample = True`, you activate various decoding strategies which influence the next token from the probability distribution over the entire vocabulary. You can then adjust the outputs changing `temperature` and other parameters (such as `top_k` and `top_p`). \n\nUncomment the lines in the cell below and rerun the code. Try to analyze the results. You can read some comments below.","metadata":{"tags":[]}},{"cell_type":"code","source":"generation_config = GenerationConfig(max_new_tokens=50)\n# generation_config = GenerationConfig(max_new_tokens=10)\n# generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=0.1)\n# generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=0.5)\n# generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=1.0)\n\ninputs = tokenizer(few_shot_prompt, return_tensors='pt')\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        generation_config=generation_config,\n    )[0], \n    skip_special_tokens=True\n)\n\nprint(dash_line)\nprint(f'MODEL GENERATION - FEW SHOT:\\n{output}')\nprint(dash_line)\nprint(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:42:16.232852Z","iopub.execute_input":"2023-08-05T17:42:16.233349Z","iopub.status.idle":"2023-08-05T17:42:20.847541Z","shell.execute_reply.started":"2023-08-05T17:42:16.233287Z","shell.execute_reply":"2023-08-05T17:42:20.845762Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nMODEL GENERATION - FEW SHOT:\n#Person1 wants to upgrade his system. #Person2 wants to add a painting program to his software. #Person1 wants to upgrade his hardware.\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Comments related to the choice of the parameters in the code cell above:\n- Choosing `max_new_tokens=10` will make the output text too short, so the dialogue summary will be cut.\n- Putting `do_sample = True` and changing the temperature value you get more flexibility in the output.","metadata":{}},{"cell_type":"markdown","source":"As you can see, prompt engineering can take you a long way for this use case, but there are some limitations. Next, you will start to explore how you can use fine-tuning to help your LLM to understand a particular use case in better depth!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Performed the Exercise below :**\n\nChange the configuration parameters to investigate their influence on the output. \n\nPutting the parameter `do_sample = True`, you activate various decoding strategies which influence the next token from the probability distribution over the entire vocabulary. You can then adjust the outputs changing `temperature` and other parameters (such as `top_k` and `top_p`). \n\nUncomment the lines in the cell below and rerun the code. Try to analyze the results. You can read some comments below.","metadata":{}},{"cell_type":"markdown","source":"**Observation after performing the exercise**\n- Max new tokes sometimes provide the good summary\n- Most of the cases below, model does not summarize well.","metadata":{}},{"cell_type":"code","source":"# generation_config = GenerationConfig(max_new_tokens=50)\ngeneration_config = GenerationConfig(max_new_tokens=10)\n# generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=0.1)\n# generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=0.5)\n# generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=1.0)\n\ninputs = tokenizer(few_shot_prompt, return_tensors='pt')\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        generation_config=generation_config,\n    )[0], \n    skip_special_tokens=True\n)\n\nprint(dash_line)\nprint(f'MODEL GENERATION - FEW SHOT:\\n{output}')\nprint(dash_line)\nprint(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:42:20.849684Z","iopub.execute_input":"2023-08-05T17:42:20.850186Z","iopub.status.idle":"2023-08-05T17:42:23.748789Z","shell.execute_reply.started":"2023-08-05T17:42:20.850137Z","shell.execute_reply":"2023-08-05T17:42:23.747419Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nMODEL GENERATION - FEW SHOT:\n#Person1 wants to upgrade his system.\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# generation_config = GenerationConfig(max_new_tokens=50)\n# generation_config = GenerationConfig(max_new_tokens=10)\ngeneration_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=0.1)\n# generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=0.5)\n# generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=1.0)\n\ninputs = tokenizer(few_shot_prompt, return_tensors='pt')\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        generation_config=generation_config,\n    )[0], \n    skip_special_tokens=True\n)\n\nprint(dash_line)\nprint(f'MODEL GENERATION - FEW SHOT:\\n{output}')\nprint(dash_line)\nprint(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:42:23.750639Z","iopub.execute_input":"2023-08-05T17:42:23.754112Z","iopub.status.idle":"2023-08-05T17:42:26.988014Z","shell.execute_reply.started":"2023-08-05T17:42:23.754070Z","shell.execute_reply":"2023-08-05T17:42:26.986637Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nMODEL GENERATION - FEW SHOT:\n#Person1 wants to upgrade his system and hardware.\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# generation_config = GenerationConfig(max_new_tokens=50)\n# generation_config = GenerationConfig(max_new_tokens=10)\n# generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=0.1)\ngeneration_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=0.5)\n# generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=1.0)\n\ninputs = tokenizer(few_shot_prompt, return_tensors='pt')\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        generation_config=generation_config,\n    )[0], \n    skip_special_tokens=True\n)\n\nprint(dash_line)\nprint(f'MODEL GENERATION - FEW SHOT:\\n{output}')\nprint(dash_line)\nprint(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:42:26.991922Z","iopub.execute_input":"2023-08-05T17:42:26.992720Z","iopub.status.idle":"2023-08-05T17:42:31.742992Z","shell.execute_reply.started":"2023-08-05T17:42:26.992674Z","shell.execute_reply":"2023-08-05T17:42:31.741696Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nMODEL GENERATION - FEW SHOT:\n#Person1 suggests upgrading the system and adding a painting program to it. #Person2 suggests adding a painting program to it.\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# generation_config = GenerationConfig(max_new_tokens=50)\n# generation_config = GenerationConfig(max_new_tokens=10)\n# generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=0.1)\n# generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=0.5)\ngeneration_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=1.0)\n\ninputs = tokenizer(few_shot_prompt, return_tensors='pt')\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        generation_config=generation_config,\n    )[0], \n    skip_special_tokens=True\n)\n\nprint(dash_line)\nprint(f'MODEL GENERATION - FEW SHOT:\\n{output}')\nprint(dash_line)\nprint(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:42:31.744713Z","iopub.execute_input":"2023-08-05T17:42:31.745124Z","iopub.status.idle":"2023-08-05T17:42:35.913776Z","shell.execute_reply.started":"2023-08-05T17:42:31.745089Z","shell.execute_reply":"2023-08-05T17:42:35.912395Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nMODEL GENERATION - FEW SHOT:\n#Person2 thinks about upgrading their software, so they want to install a printing program and a graphics program.\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# generation_config = GenerationConfig(max_new_tokens=50)\n# generation_config = GenerationConfig(max_new_tokens=10)\n# generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=0.1)\n# generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=0.5)\ngeneration_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=1.0,\n                                    top_k=1, top_p=0.2)\n\ninputs = tokenizer(few_shot_prompt, return_tensors='pt')\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        generation_config=generation_config,\n    )[0], \n    skip_special_tokens=True\n)\n\nprint(dash_line)\nprint(f'MODEL GENERATION - FEW SHOT:\\n{output}')\nprint(dash_line)\nprint(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:42:35.916142Z","iopub.execute_input":"2023-08-05T17:42:35.917032Z","iopub.status.idle":"2023-08-05T17:42:40.784962Z","shell.execute_reply.started":"2023-08-05T17:42:35.916985Z","shell.execute_reply":"2023-08-05T17:42:40.783488Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nMODEL GENERATION - FEW SHOT:\n#Person1 wants to upgrade his system. #Person2 wants to add a painting program to his software. #Person1 wants to upgrade his hardware.\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=1.0,\n                                    top_k=10, top_p=0.5)\n\ninputs = tokenizer(few_shot_prompt, return_tensors='pt')\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        generation_config=generation_config,\n    )[0], \n    skip_special_tokens=True\n)\n\nprint(dash_line)\nprint(f'MODEL GENERATION - FEW SHOT:\\n{output}')\nprint(dash_line)\nprint(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:42:40.787129Z","iopub.execute_input":"2023-08-05T17:42:40.788032Z","iopub.status.idle":"2023-08-05T17:42:44.034621Z","shell.execute_reply.started":"2023-08-05T17:42:40.787984Z","shell.execute_reply":"2023-08-05T17:42:44.033045Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nMODEL GENERATION - FEW SHOT:\n#Person1 wants to upgrade his computer and hardware.\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=0.1,\n                                    top_k=10, top_p=0.01)\n\ninputs = tokenizer(few_shot_prompt, return_tensors='pt')\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        generation_config=generation_config,\n    )[0], \n    skip_special_tokens=True\n)\n\nprint(dash_line)\nprint(f'MODEL GENERATION - FEW SHOT:\\n{output}')\nprint(dash_line)\nprint(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:42:44.036723Z","iopub.execute_input":"2023-08-05T17:42:44.037477Z","iopub.status.idle":"2023-08-05T17:42:48.961499Z","shell.execute_reply.started":"2023-08-05T17:42:44.037437Z","shell.execute_reply":"2023-08-05T17:42:48.960269Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nMODEL GENERATION - FEW SHOT:\n#Person1 wants to upgrade his system. #Person2 wants to add a painting program to his software. #Person1 wants to upgrade his hardware.\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"generation_config = GenerationConfig(max_new_tokens=10, do_sample=True, temperature=0.1,\n                                    top_k=10, top_p=0.01)\n\ninputs = tokenizer(few_shot_prompt, return_tensors='pt')\noutput = tokenizer.decode(\n    model.generate(\n        inputs[\"input_ids\"],\n        generation_config=generation_config,\n    )[0], \n    skip_special_tokens=True\n)\n\nprint(dash_line)\nprint(f'MODEL GENERATION - FEW SHOT:\\n{output}')\nprint(dash_line)\nprint(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-05T17:42:48.963483Z","iopub.execute_input":"2023-08-05T17:42:48.964470Z","iopub.status.idle":"2023-08-05T17:42:51.998400Z","shell.execute_reply.started":"2023-08-05T17:42:48.964412Z","shell.execute_reply":"2023-08-05T17:42:51.996379Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nMODEL GENERATION - FEW SHOT:\n#Person1 wants to upgrade his system.\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\n#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Summary of hands on experience\n- Zero and one shot learning works fine. Adding more and more number of shots does not work well","metadata":{}}]}